# Wenqi Jiang

Data Engineer / Backend Engineer

## About Me

My name is Wenqi Jiang. I'm a software engineer with 3 years' experience in **big data** infrastructure and **backend** services, specializing in scalability, high availability, and low latency distributed systems design and implementation. I am proficient in `Java` and `Scala`.

Currently, I'm working with the Ontology Engineering Group (OEG) and studying for a master's degree in Data Science from the Polytechnic University of Madrid (UPM). In addition to my regular duties, I am constantly searching for new challenges. I have learned to `react` and `flutter`.

### Contact

- Mobile: KzM0IDY5MS03NTItMTU3
- Email: [jiangwenqi1995@gmail.com](mailto:jiangwenqi1995@gmail.com)
- Online Resume: [jiangwenqi.info](https://jiangwenqi.info/)
- GitHub: [github.com/jiangwenqi](https://github.com/jiangwenqi)
- Blog: [dev.to/jiangwenqi](https://dev.to/jiangwenqi)

---

## Experience and Projects

### Ontology Engineer (Scholarship)

**[OEG-UPM](https://oeg.fi.upm.es)** | _Dec. 2021 - Present_

#### [LOOM-LD](https://github.com/oeg-upm/loom-ld)

> A student scholarship for the development of linking algorithms and graph linkers.

- Analyzed ontologies from different data sources;
- Specialized 7 linking discovery algorithms, including text similarity and spatial relationships;
- Implemented a Sparql-based knowledge graph linker using customized `Apache Jena` functions;
- Evaluated those algorithms with **_OAEI-2021_** datasets;
- Completed the master's thesis.

**_Keywords_**: Ontology, Graph Linker, RDF, SPARQL, Apache Jena, Text Similarity, DE-9IM, WKT, OAEI

---

### Big Data Engineer

**[TOGIC](http://www.51togic.com)** | _May 2019 - Aug. 2021_ · 2 yrs 4 mos

#### Offline Data Warehouse

- The data warehouse contains over **200 TB** of data and more than 150 tables, including user activity logs and system logs from the Togic App and Webox System, which generate over **300 GB** of data every day.
- The data warehouse structure is **STAR** modelling and is organized into four layers: ODS, DWD, DWS, and ADS, which saved over **80%** storage space and eased the small files' problem on `HDFS`.

**_Keywords_**: `CDH` `Kafka` `HDFS` `HIVE` `Spark`

#### Data Statistics System

- The statistics system was **restructured** based on the new Offline Data Warehouse, and almost all big data components **upgraded**, including `HDFS`, `Spark`, `Kafka` etc.;
- The code was rewritten by using **DataFrames**, and was more readable and maintainable, which **reduced the process time** to 1/4 of the previous one.
- Implemented more than **30 new statistical items** and generated reports;
- Fixed the bugs that the former system caused.

**_Keywords_**: `Sqoop` `Hive` `Spark SQL` `Scala` `Elasticsearch` `MySQL` `MongoDB` `Python`

#### Log Collection Service

- **Restructured** the log collection service to improve performance and stability;

- Used `Nginx` and `Netty` to receive and forward logs, and handle error data;

- Produced all logs into the message queue of `Kafka`, which has five brokers, three data backups, and seven days of log redundancy to **improve the robustness** of this service.

**_Keywords_**: `Nginx` `Netty` `Java` `Kafka` `HDFS`

### Backend Engineer

**[WEBSTUDIO](http://www.wbdatavis.com)** | _Jul. 2018 - Apr. 2019_ · 10 mos

- Implemented backend APIs of big data visualization dashboards and general reports for the `BI` applications;
- Developed more than 30 **data operators**, such as summation, date conversion, string processing etc.;
- Implemented the one-click function of syncing all user information;
- Expanded 16 data sources, including `MySQL`, `SQL Server`, `MongoDB` etc.;
- Built and maintained the big data platform;
- Fixed bugs and developed **new features** for the previous company's projects.

**_Keywords_**: `Dubbo` `Spring Boot` `MyBatis` `Hibernate` `Java` `Nginx` `MySQL` `Redis` `Docker` `FastDFS` `CDH` `Hadoop` `HBase` `Impala` `Spark ML`

### Software Engineer (Internship)

**[KEG-THU](https://keg.cs.tsinghua.edu.cn)** | _Feb. 2018 - Jul. 2018_ · 6 mos

- Organized and annotated critical illness insurance documents;
- Trained models to extract the logical structure of insurance documents by using `GROBID`;
- Created a desktop application using above models;
- Maintained datasets in `NoSQL database`, like MongoDB, Neo4j;
- Completed the thesis.

**_Keywords_**: `NLP` `CRF` `GROBID` `Neo4j` `MongoDB` `Java FX`

---

## Open Source

### Dapp-Learning

**[Dapp Learning DAO](https://github.com/Dapp-Learning-DAO)** | _Apr. 2022 - Present_

- Contributions of various tutorial tasks;
- Translations of the basic tasks;
- Shares of the latest blockchain news and cutting-edge technics in community.

**_Keywords_**: `Blockchain` `web3.js` `Solidity` `Dapp` `Ethereum` `Hardhat` `Alchemy` `Infura` `DAO`.

---

## Education

### MS Data Science

**Polytechnic University of Madrid** | _2021 - Present_

### BE Computer Science & Technology

**Beijing Information Science & Technology University** | _2014 - 2018_