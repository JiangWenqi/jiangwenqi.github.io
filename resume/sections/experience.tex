%====================
% EXPERIENCE A
%====================
\subsection{{Software Engineer (Scholarship) | \href{https://oeg.fi.upm.es}{OEG-UPM} \hfill Jan. 2022 - Jul. 2022}}
\subtext{\href{https://github.com/oeg-upm/loom-ld}{LOOM-LD} \hfill Madrid, Spain}
\begin{zitemize}
    \item  Analyzed ontologies from different graph data sources, like DBpedia, Wikidata;
    \item  Specialized 7 linking discovery algorithms, including string-based similarity and geometry relationships;
    \item  Implemented a SPARQL-based linking application by using Apache Jena, and evaluated it with the OAEI-2021 datasets;
    \item  Written the master's \href{https://oa.upm.es/71452/}{thesis}.
\end{zitemize}

%====================
% EXPERIENCE B
%====================
\subsection{{Big Data Engineer | \href{http://www.51togic.com}{TOGIC} \hfill May 2019 - Aug. 2021}}
\subtext{Offline Data Warehouse \hfill Shenzhen, China}
\begin{zitemize}
    \item Maintained the Hadoop cluster containing over 200 TB of data, including user and system logs from 3 different sources;
    \item Upgraded big data components, like Hadoop, Spark, Kafka, etc., and monitored them on CDH;
    \item Designed and implemented a four-layer data warehouse based on the STAR model by using Hive, which had near 150 tables and received over 300 GB per day;
    \item Rewrote the ETL pipeline, which saved over 80\% of storage and fixed the small files' problem on HDFS.
\end{zitemize}
\subtext{Data Statistics System}
\begin{zitemize}
    \item Restructured the statistics system based on the new offline data warehouse;
    \item Rewrote the code by using Spark DSL, making it more readable and maintainable;
    \item Optimized the system's performance, reduced the process time by 25\% compared to the previous version;
    \item Implemented more than 30 new statistical demands and fixed bugs.
\end{zitemize}
\subtext{Log Collection Service}
\begin{zitemize}
    \item Designed and implemented the log collection pipeline using Nginx and Netty, improving performance, stability, and scalability;
    \item Processed all logs into the Kafka cluster, which has 5 brokers, 3 replications, and 7 days of redundancy, improving robustness.
\end{zitemize}



%====================
% EXPERIENCE C
%====================
\subsection{{Backend Engineer | \href{http://www.wbdatavis.com/}{WEBSTUDIO} \hfill Jul. 2018 - Apr. 2019}}
\begin{zitemize}
    \item Implemented backend APIs of big data visualization dashboards and general reports for the BI applications; \hfill \textit{Beijing, China}
    \item Developed more than 25 data operators, such as summation, date conversion, string processing etc.;
    \item Implemented the one-click function of syncing all user information;
    \item Expanded 16 data sources, including MySQL, SQL Server, MongoDB etc.;
    \item Maintained the big data cluster;
    \item Fixed bugs and developed new features for the previous projects.
\end{zitemize}

%====================
% EXPERIENCE D
%====================
\subsection{{Software Engineering Intern | \href{https://keg.cs.tsinghua.edu.cn/}{KEG-THU} \hfill Feb. 2018 - Jul. 2018}}

\begin{zitemize}
    \item Organized and annotated critical illness insurance documents;\hfill \textit{Beijing, China}
    \item Trained models to extract the logical structure of insurance documents by using GROBID;
    \item Created a desktop application using above models;
    \item Maintained datasets in NoSQL database, like MongoDB, Neo4j;
    \item Completed the thesis.
\end{zitemize}

%====================
% EXPERIENCE E
%====================
%\subsection{{ROLE / PROJECT E \hfill MMM YYYY --- MMM YYYY}}
%\subtext{company E \hfill somewhere, state}
%\begin{zitemize}
%\item In lobortis libero consectetur eros vehicula, vel pellentesque quam fringilla.
%\item Ut malesuada purus at mi placerat dapibus.
%\item Suspendisse finibus massa eu nisi dictum, a imperdiet tellus convallis.
%\item Nam feugiat erat vestibulum lacus feugiat, efficitur gravida nunc imperdiet.
%\item Morbi porta lacus vitae augue luctus, a rhoncus est sagittis.
%\end{zitemize}
